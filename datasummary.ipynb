{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10 20']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"how 30 10 20 word\"\n",
    "\n",
    "pattern = r\"(?<=\\s)\\d+\\s\\d+(?!\\s*\\d)\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "print(matches)  # Output: ['10 20']\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pcba-aid1030', '15963', '200920', 'other', 'enzyme', 'ALDH1A1']\n",
      "['pcba-aid2546', '10550', '293509', 'transcription', 'factor', 'VP16']\n",
      "['pcba-aid2551', '16666', '288772', 'transcription', 'factor', 'ROR', 'gamma']\n",
      "['pcba-aid485364', '10700', '345950', 'other', 'enzyme', 'TGR']\n",
      "['pcba-aid504332', '30586', '317753', 'other', 'enzyme', 'G9a']\n",
      "['pcba-aid504333', '15670', '341165', 'protein-protein', 'interaction', 'BAZ2B']\n",
      "['pcba-aid504339', '16857', '367661', 'protein-protein', 'interaction', 'JMJD2A']\n",
      "['pcba-aid588342', '25034', '335826', 'other', 'enzyme', 'luciferase']\n",
      "['pcba-aid686978', '62746', '354086', 'viability', 'DT40-hTDP1']\n",
      "['pcba-aid686979', '48816', '368048', 'viability', 'DT40-hTDP1']\n",
      "['pcba-aid720504', '10170', '353881', 'protein', 'kinase', 'Plk1', 'PBD']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "new_lines = []\n",
    "with open('datasets_summary.txt', 'r') as f:\n",
    "    data_lines = f.readlines()\n",
    "    regex = re.compile(r'(?<!\\S)\\d+(?!\\S)')\n",
    "    # count the number of matches for each line with the regex\n",
    "    count_list = [len(regex.findall(line)) for line in data_lines]\n",
    "    \n",
    "\n",
    "    \n",
    "for sentence, match_count in zip(data_lines, count_list):\n",
    "    if match_count == 3:\n",
    "        words = sentence.split()\n",
    "        # find matches in each word and their index\n",
    "        matches = [regex.findall(word) for word in words]\n",
    "        matches = [match for match in matches if match]\n",
    "        # find the index of the word with the match\n",
    "        index = [i for i, word in enumerate(words) if regex.findall(word)]\n",
    "        new_number = words[index[1]] + words[index[2]]\n",
    "        new_words = words[:index[1]] + [new_number] + words[index[2]+1:]\n",
    "        new_lines.append(' '.join(new_words))\n",
    "    elif match_count == 4:\n",
    "        words = sentence.split()\n",
    "        # find matches in each word and their index\n",
    "        matches = [regex.findall(word) for word in words]\n",
    "        matches = [match for match in matches if match]\n",
    "        # find the index of the word with the match\n",
    "        index = [i for i, word in enumerate(words) if regex.findall(word)]\n",
    "        new_number1 = words[index[0]] + words[index[1]]\n",
    "        new_number2 = words[index[2]] + words[index[3]]\n",
    "        new_words = words[:index[0]] + [new_number1] +[new_number2] + words[index[3]+1:]\n",
    "        print(new_words)\n",
    "        new_lines.append(' '.join(new_words))\n",
    "\n",
    "    else:\n",
    "        new_lines.append(sentence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_lines = [' '.join(line.split()[:5]) for line in new_lines]\n",
    "for idx in range(len(new_lines)):\n",
    "    if '\\n' not in new_lines[idx]:\n",
    "        new_lines[idx] += '\\n'\n",
    "\n",
    "with open('datasets_summary_cleaned_new.txt', 'w') as f:\n",
    "    for line in new_lines:\n",
    "        f.write(line)\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7n/ynz1z7qd3fbg7568r_zgsb980000gn/T/ipykernel_38652/4156056479.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('datasets_summary_cleaned_new.txt', sep=' ',error_bad_lines=False, warn_bad_lines=False)\n",
      "/var/folders/7n/ynz1z7qd3fbg7568r_zgsb980000gn/T/ipykernel_38652/4156056479.py:2: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('datasets_summary_cleaned_new.txt', sep=' ',error_bad_lines=False, warn_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "#read txt csv with delimeter ' ', ignore columns more that header length\n",
    "df = pd.read_csv('datasets_summary_cleaned_new.txt', sep=' ',error_bad_lines=False, warn_bad_lines=False)\n",
    "df['Count'] = df['Actives'] + df['Inactives']\n",
    "df['% hit'] = df['Actives'] / df['Count']\n",
    "\n",
    "df = df[['Dataset', 'Actives', 'Inactives', 'Count', '% hit']]\n",
    "df.to_csv('data_summary_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
